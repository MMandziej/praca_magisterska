filter = "bottom",
escape = F,
options = list(
dom = "Blfrtip",
scrollX = T,
lengthMenu = list(c(10, 20, 50, -1), # declare values
c(10, 20,50, "All")), # declare titles # end of lengthMenu customization
pageLength = 10)) %>%
formatPercentage(digits = 2,columns = c(1, 2, 3))
return(table)
} else {
dataset[is.na(dataset[,feature]), feature] = 'N/A'
table = as.data.frame(prop.table(table(dataset[,feature])))
colnames(table) = c(feature, "Frequency")
table$Frequency = round(table$Frequency, 4)
table = datatable(table,
filter = "bottom",
escape = F,
options = list(dom = "Blfrtip",
scrollX = T,
lengthMenu = list(c(10, 20, 50, -1), # declare values
c(10, 20, 50, "All")), # declare titles # end of lengthMenu customization
pageLength = 10)) %>%
formatPercentage(digits = 2, columns = c(2))
return(table)
}
} else {
overall = data.frame(matrix(nrow = 10, ncol = 2))
colnames(overall) = c("Measure", "Value")
overall[,1] = c("Min", "Max"," Mean", "Median", "1st Quartile", "3rd Quartile",
"Missing values", "St.Dev", "Skewness", "Kurtosis")
overall[,2] = c(min(dataset[,feature], na.rm = T),
max(dataset[,feature], na.rm = T),
base::mean(dataset[,feature], na.rm = T),
median(dataset[,feature], na.rm = T),
quantile(dataset[,feature], probs = 0.25, na.rm = T),
quantile(dataset[,feature], probs = 0.75, na.rm = T),
sum(is.na(dataset[,feature])),
sd(dataset[,feature], na.rm = T),
skewness(dataset[,feature], na.rm = T),
kurtosis(dataset[,feature], na.rm = T))
overall = datatable(overall,
filter = "bottom",
escape = F,
options = list(dom = "Blfrtip",
scrollX = T,
lengthMenu = list(c(10, 20 ,50, -1), # declare values
c(10, 20, 50, "All")), # declare titles # end of lengthMenu customization
pageLength = 10))
return(overall)
}
}
# CALCULATE AUC
CalculateAUC <- function(models_list){
output = as.data.frame(matrix(nrow = length(models_list), ncol=2))
colnames(output) = c("Dataset", "AUC")
if (length(models_list) == 6) {
output[,1]=c("Test all features", "Train all features", "Test selected features", "Train selected features",
"Test no population", "Train no population")
} else if(length(models_list) == 2) {
output[,1] = c("Test", "Train")
} else {
output[,1] = c("Gradient Boosted Machine", "Neural Network", "Regression Random Forest",
"Penalized Regression", "Classification Random Forest")
}
for (i in (1:length(models_list))) {
output[i,2] = fastAUC(models_list[[i]]['Score'], models_list[[i]]['Label'])
}
output = datatable(output, rownames = FALSE, options = list(dom = 't', pageLength = -1),
caption = htmltools::tags$caption(
style = 'caption-side: top; text-align: center; font-size:16px;font-weight: bold; color:black;',
'Area under curve')) %>%
formatRound(digits = 2, columns = 2)
return(output)
}
# FAST AUC
fastAUC <- function(probs, class) {
x <- probs
y <- class
x1 = x[y==1]; n1 = length(x1);
x2 = x[y==0]; n2 = length(x2);
r = rank(c(x1,x2))
auc = (sum(r[1:n1]) - n1*(n1+1)/2) / n1 / n2
return(auc)
}
# PLOT MODEL PERFORMANCE
plot_model_performance <- function(results_list, red_cut_off=0.3, amber_cut_off=0.7){
model_perf = plot_ly(
x=results_list[[1]]$X_coordinates,
y=results_list[[1]]$y_coordinates,
type='scatter',
mode='line',
name="Test dataset",
line=list(color='#197519')) %>% #'#dd4b39'
add_trace(
x=results_list[[2]]$X_coordinates,
y=results_list[[2]]$y_coordinates,
name="Train dataset",
line=list(color='#2a88ad')) %>% # 'rgb(255, 153, 0)'
add_segments(x=red_cut_off,
xend=red_cut_off,
y=0, yend=1,
name="Red bucket",
line=list(color='#a83e32', width=3)) %>%
add_segments(x=amber_cut_off,
xend=amber_cut_off,
y=0, yend=1,
name="Amber bucket",
line=list(color='#e8b43a', width=3)) %>%
layout(title='<b>Model performance</b>',
titlefont=list(size=22,
color='black',
face='bold'),
margin=list(t=50),
xaxis=list(tickformat="%",
title="% of cases"),
yaxis=list(tickformat="%",
title="% of errors found"))
return(model_perf)
}
# CUT OFF DISTRIBUTION TABLE
cut_off_distribution_table <- function(results_list,
red_cut_off=0.3,
amber_cut_off=0.7){
# DIVIDE TRAIN AND TEST DATA
train_dataset <- results_list[[2]]
test_dataset <- results_list[[1]]
# GET SUM OF POSITIVE OBSERVATIONS ON BOTH DATASETS
train_labels <- sum(train_dataset$Label)
test_labels <- sum(test_dataset$Label)
# DISTINGUISH CUT OFFS
red_train <- train_dataset %>% filter(X_coordinates <= red_cut_off)
red_test <- test_dataset %>% filter(X_coordinates <= red_cut_off)
amber_train <- train_dataset %>% filter(X_coordinates > red_cut_off, X_coordinates <= amber_cut_off)
amber_test <- test_dataset %>% filter(X_coordinates > red_cut_off, X_coordinates <= amber_cut_off)
green_train <- train_dataset %>% filter(X_coordinates > amber_cut_off)
green_test <- test_dataset %>% filter(X_coordinates > amber_cut_off)
# CALCULATE ERROR COUNTS AND PERCENTAGES IN BUCKEST
buckets <- c('Red', 'Amber', 'Green')
cases_count_train <- c(nrow(red_train), nrow(amber_train), nrow(green_train))
error_count_train <- c(sum(red_train$Label), sum(amber_train$Label), sum(green_train$Label))
error_perc_train <- c(round(sum(red_train$Label) / train_labels, 3)*100,
round(sum(amber_train$Label) / train_labels, 3)*100,
round(sum(green_train$Label) / train_labels, 3)*100)
cases_count_test <- c(nrow(red_test), nrow(amber_test), nrow(green_test))
error_count_test <- c(sum(red_test$Label), sum(amber_test$Label), sum(green_test$Label))
error_perc_test <- c(round(sum(red_test$Label) / test_labels, 3)*100,
round(sum(amber_test$Label) / test_labels, 3)*100,
round(sum(green_test$Label) / test_labels, 3)*100)
# create output table
output_table <- data.frame(buckets, cases_count_train, error_count_train, error_perc_train,
cases_count_test, error_count_test, error_perc_test)
names(output_table)[names(output_table) == "buckets"] <- "Bucket"
names(output_table)[names(output_table) == "cases_count_train"] <- "Cases train [count]"
names(output_table)[names(output_table) == "error_count_train"] <- "Errors train [count]"
names(output_table)[names(output_table) == "error_perc_train"] <- "Errors train [%]"
names(output_table)[names(output_table) == "cases_count_test"] <- "Cases test [count]"
names(output_table)[names(output_table) == "error_count_test"] <- "Errors test [count]"
names(output_table)[names(output_table) == "error_perc_test"] <- "Errors test [%]"
return(output_table)
}
### DISPLAY DATA IN AI ASSITANT ###
AI_Assistant(dataset = dataset_fs,
stage = 'Model_results',
Variable_importance_all_methods = Variable_importance_all_methods_merged,
colnames_feature_selection = colnames_fs, #colnames(dataset_dummy_cat1), # colnames(dataset_dummy)
nn_results = nn_results1,
gbm_results = gbm_results1,
rf_results = rf_results1)
library(RColorBrewer)
library(RCurl)
#library(readxl)
library(dplyr)
library(ggplot2)
library(readr)
library(shinyWidgets)
library(plotly)
library(shiny)
library(DT)
library(shinythemes)
library(tidyr)
library(shinyjs)
library(shinyalert)
library(formattable)
library(shinydashboard)
library(stringr)
library(e1071)
library(dashboardthemes)
library(rpart)
library(rpart.plot)
library(naniar)
setwd("C:/Users/mmandziej001/Desktop/FCU/SCRIPTS/predictive_qc_lion_king/model_training/scripts/docker_app")
load("pc_app_data.RData")
AI_Assistant = dget("AI_Assistant_LK_app.R")
# basic_plots = dget("basic_plots.R")
# basic_statistics_exploratory_analysis = dget("basic_statistics_exploratory_analysis.R")
# histogram_exploratory_analysis = dget("histogram_exploratory_analysis.R")
# boxplot_exploratory_analysis = dget("boxplot_exploratory_analysis.R")
# CalculateAUC = dget("CalculateAUC.R")
# fastAUC = dget("fastAUC.R")
# plot_model_performance = dget("plot_model_performance.R")
# cut_off_distribution_table = dget("cut_off_distribution_table.R")
"""
# BASIC PLOTS
basic_plots <- function(type, ...){
if (type == 'histogram') {
histogram_exploratory_analysis(...)
} else {
boxplot_exploratory_analysis(...)
}
}
# BOXPLOT EXPLANATORY ANALYSIS
boxplot_exploratory_analysis <- function(feature, dataset,Label=F){
if(is.numeric(dataset[,feature])==F){
plot_ly(y=dataset[,'Label'],x=dataset[,feature],color=dataset[,feature],type="box",height = 600)%>%
layout(showlegend=F,yaxis=list(title='Label'),xaxis=list(title=feature))
}else{
plot_ly(dataset,y=dataset[,feature],type="box",name=feature,height = 600)%>%
layout(showlegend=F,yaxis=list(title=feature))
}
}
# HISTOGRAM EXPLANATORY ANALYSIS
histogram_exploratory_analysis <- function(feature,dataset,bins=50,Label=T){
if(Label==T){
if(is.numeric(dataset[,feature])){
test=hist(dataset[,feature])
test_0=hist(dataset[,feature][which(dataset$Label==0)],breaks = test$breaks)
test_1=hist(dataset[,feature][which(dataset$Label==1)],breaks = test$breaks)
plot_ly(x=test_0$breaks[-1],
y=test_0$counts,
type="bar",name = "Label = 0",textposition = 'auto',text=paste(100*round(test_0$counts/(test_0$counts+test_1$counts),2),"%",sep = "")
,marker=list(color='#dd4b39')
)%>%
add_trace(x=test_1$breaks[-1],
y=test_1$counts,
name = "Label = 1",text=paste(100*round(test_1$counts/(test_0$counts+test_1$counts),2),"%",sep = "")
,marker=list(color='#FFB600')
)%>%
layout(#margin = list(b = 500),
yaxis=list(title="Amount of cases"
#,color='white'
),xaxis=list(title=feature,
tickangle = 45
#,color='white'
),title=paste("Histogram of ",feature,sep=""),
barmode="stack"
#,font=list(color='white')
)
}else{
dataset[,feature]=as.character(dataset[,feature])
dataset[is.na(dataset[,feature]),feature]='N/A'
plot_ly(x=sort(unique(dataset[which(dataset$Label==0),feature])),
y=table(dataset[which(dataset$Label==0),feature]),
type="bar",name = "Label = 0",textposition = 'auto',
text=paste(100*round(table(dataset[which(dataset$Label==0),feature])/table(dataset[which(dataset[,feature]%in%dataset[which(dataset$Label==0),feature]),feature]),2),"%",sep = "")
,marker=list(color='#dd4b39')
)%>%
add_trace(x=sort(unique(dataset[which(dataset$Label==1),feature])),
y=table(dataset[which(dataset$Label==1),feature]),
name = "Label = 1",
text=paste(100*round(table(dataset[which(dataset$Label==1),feature])/table(dataset[which(dataset[,feature]%in%dataset[which(dataset$Label==1),feature]),feature]),2),"%",sep = "")
,marker=list(color='#FFB600')
)%>%
layout(#margin = list(b = 500),
yaxis=list(
title=HTML("<b>Amount of cases</b>")
#,color='white'
)
,xaxis=list(
title=HTML(paste("<b>",feature,sep='')),
tickangle = 45
#,color='white'
),title=HTML(
paste("<b>Histogram of ",feature,sep=""))
,barmode="stack"
#,font=list(color='white')
)
}
} else {
plot_ly(x=dataset[,feature],type="histogram",nbinsx=bins)%>%
layout(yaxis=list(
title=HTML("<b>Amount of cases</b>")
#,color='white'
),
xaxis=list(
title=HTML(paste("<b>",feature,sep='')),
tickangle = 45
#,color='white'
),
title=paste("Histogram of ",feature,sep=""),
barmode="stack")
}
}
# BASIC STATISTICS EXPLANATORY ANALYSIS
basic_statistics_exploratory_analysis <- function(feature, dataset, Label = T) {
if (is.numeric(dataset[,feature]) == F) {
if (Label == T) {
dataset[is.na(dataset[,feature]), feature] = 'N/A'
table = round(as.data.frame.matrix(addmargins(prop.table(table(dataset[,feature],dataset$Label)),
margin = 2)),4)
table = datatable(table,
filter = "bottom",
escape = F,
options = list(
dom = "Blfrtip",
scrollX = T,
lengthMenu = list(c(10, 20, 50, -1), # declare values
c(10, 20,50, "All")), # declare titles # end of lengthMenu customization
pageLength = 10)) %>%
formatPercentage(digits = 2,columns = c(1, 2, 3))
return(table)
} else {
dataset[is.na(dataset[,feature]), feature] = 'N/A'
table = as.data.frame(prop.table(table(dataset[,feature])))
colnames(table) = c(feature, "Frequency")
table$Frequency = round(table$Frequency, 4)
table = datatable(table,
filter = "bottom",
escape = F,
options = list(dom = "Blfrtip",
scrollX = T,
lengthMenu = list(c(10, 20, 50, -1), # declare values
c(10, 20, 50, "All")), # declare titles # end of lengthMenu customization
pageLength = 10)) %>%
formatPercentage(digits = 2, columns = c(2))
return(table)
}
} else {
overall = data.frame(matrix(nrow = 10, ncol = 2))
colnames(overall) = c("Measure", "Value")
overall[,1] = c("Min", "Max"," Mean", "Median", "1st Quartile", "3rd Quartile",
"Missing values", "St.Dev", "Skewness", "Kurtosis")
overall[,2] = c(min(dataset[,feature], na.rm = T),
max(dataset[,feature], na.rm = T),
base::mean(dataset[,feature], na.rm = T),
median(dataset[,feature], na.rm = T),
quantile(dataset[,feature], probs = 0.25, na.rm = T),
quantile(dataset[,feature], probs = 0.75, na.rm = T),
sum(is.na(dataset[,feature])),
sd(dataset[,feature], na.rm = T),
skewness(dataset[,feature], na.rm = T),
kurtosis(dataset[,feature], na.rm = T))
overall = datatable(overall,
filter = "bottom",
escape = F,
options = list(dom = "Blfrtip",
scrollX = T,
lengthMenu = list(c(10, 20 ,50, -1), # declare values
c(10, 20, 50, "All")), # declare titles # end of lengthMenu customization
pageLength = 10))
return(overall)
}
}
# CALCULATE AUC
CalculateAUC <- function(models_list){
output = as.data.frame(matrix(nrow = length(models_list), ncol=2))
colnames(output) = c("Dataset", "AUC")
if (length(models_list) == 6) {
output[,1]=c("Test all features", "Train all features", "Test selected features", "Train selected features",
"Test no population", "Train no population")
} else if(length(models_list) == 2) {
output[,1] = c("Test", "Train")
} else {
output[,1] = c("Gradient Boosted Machine", "Neural Network", "Regression Random Forest",
"Penalized Regression", "Classification Random Forest")
}
for (i in (1:length(models_list))) {
output[i,2] = fastAUC(models_list[[i]]['Score'], models_list[[i]]['Label'])
}
output = datatable(output, rownames = FALSE, options = list(dom = 't', pageLength = -1),
caption = htmltools::tags$caption(
style = 'caption-side: top; text-align: center; font-size:16px;font-weight: bold; color:black;',
'Area under curve')) %>%
formatRound(digits = 2, columns = 2)
return(output)
}
# FAST AUC
fastAUC <- function(probs, class) {
x <- probs
y <- class
x1 = x[y==1]; n1 = length(x1);
x2 = x[y==0]; n2 = length(x2);
r = rank(c(x1,x2))
auc = (sum(r[1:n1]) - n1*(n1+1)/2) / n1 / n2
return(auc)
}
# PLOT MODEL PERFORMANCE
plot_model_performance <- function(results_list, red_cut_off=0.3, amber_cut_off=0.7){
model_perf = plot_ly(
x=results_list[[1]]$X_coordinates,
y=results_list[[1]]$y_coordinates,
type='scatter',
mode='line',
name="Test dataset",
line=list(color='#197519')) %>% #'#dd4b39'
add_trace(
x=results_list[[2]]$X_coordinates,
y=results_list[[2]]$y_coordinates,
name="Train dataset",
line=list(color='#2a88ad')) %>% # 'rgb(255, 153, 0)'
add_segments(x=red_cut_off,
xend=red_cut_off,
y=0, yend=1,
name="Red bucket",
line=list(color='#a83e32', width=3)) %>%
add_segments(x=amber_cut_off,
xend=amber_cut_off,
y=0, yend=1,
name="Amber bucket",
line=list(color='#e8b43a', width=3)) %>%
layout(title='<b>Model performance</b>',
titlefont=list(size=22,
color='black',
face='bold'),
margin=list(t=50),
xaxis=list(tickformat="%",
title="% of cases"),
yaxis=list(tickformat="%",
title="% of errors found"))
return(model_perf)
}
# CUT OFF DISTRIBUTION TABLE
cut_off_distribution_table <- function(results_list,
red_cut_off=0.3,
amber_cut_off=0.7){
# DIVIDE TRAIN AND TEST DATA
train_dataset <- results_list[[2]]
test_dataset <- results_list[[1]]
# GET SUM OF POSITIVE OBSERVATIONS ON BOTH DATASETS
train_labels <- sum(train_dataset$Label)
test_labels <- sum(test_dataset$Label)
# DISTINGUISH CUT OFFS
red_train <- train_dataset %>% filter(X_coordinates <= red_cut_off)
red_test <- test_dataset %>% filter(X_coordinates <= red_cut_off)
amber_train <- train_dataset %>% filter(X_coordinates > red_cut_off, X_coordinates <= amber_cut_off)
amber_test <- test_dataset %>% filter(X_coordinates > red_cut_off, X_coordinates <= amber_cut_off)
green_train <- train_dataset %>% filter(X_coordinates > amber_cut_off)
green_test <- test_dataset %>% filter(X_coordinates > amber_cut_off)
# CALCULATE ERROR COUNTS AND PERCENTAGES IN BUCKEST
buckets <- c('Red', 'Amber', 'Green')
cases_count_train <- c(nrow(red_train), nrow(amber_train), nrow(green_train))
error_count_train <- c(sum(red_train$Label), sum(amber_train$Label), sum(green_train$Label))
error_perc_train <- c(round(sum(red_train$Label) / train_labels, 3)*100,
round(sum(amber_train$Label) / train_labels, 3)*100,
round(sum(green_train$Label) / train_labels, 3)*100)
cases_count_test <- c(nrow(red_test), nrow(amber_test), nrow(green_test))
error_count_test <- c(sum(red_test$Label), sum(amber_test$Label), sum(green_test$Label))
error_perc_test <- c(round(sum(red_test$Label) / test_labels, 3)*100,
round(sum(amber_test$Label) / test_labels, 3)*100,
round(sum(green_test$Label) / test_labels, 3)*100)
# create output table
output_table <- data.frame(buckets, cases_count_train, error_count_train, error_perc_train,
cases_count_test, error_count_test, error_perc_test)
names(output_table)[names(output_table) == "buckets"] <- "Bucket"
names(output_table)[names(output_table) == "cases_count_train"] <- "Cases train [count]"
names(output_table)[names(output_table) == "error_count_train"] <- "Errors train [count]"
names(output_table)[names(output_table) == "error_perc_train"] <- "Errors train [%]"
names(output_table)[names(output_table) == "cases_count_test"] <- "Cases test [count]"
names(output_table)[names(output_table) == "error_count_test"] <- "Errors test [count]"
names(output_table)[names(output_table) == "error_perc_test"] <- "Errors test [%]"
return(output_table)
}
"""
### DISPLAY DATA IN AI ASSITANT ###
AI_Assistant(dataset = dataset_fs,
stage = 'Model_results',
Variable_importance_all_methods = Variable_importance_all_methods_merged,
colnames_feature_selection = colnames_fs, #colnames(dataset_dummy_cat1), # colnames(dataset_dummy)
nn_results = nn_results1,
gbm_results = gbm_results1,
rf_results = rf_results1)
library(RColorBrewer)
library(RCurl)
#library(readxl)
library(dplyr)
library(ggplot2)
library(readr)
library(shinyWidgets)
library(plotly)
library(shiny)
library(DT)
library(shinythemes)
library(tidyr)
library(shinyjs)
library(shinyalert)
library(formattable)
library(shinydashboard)
library(stringr)
library(e1071)
library(dashboardthemes)
library(rpart)
library(rpart.plot)
library(naniar)
setwd("C:/Users/mmandziej001/Desktop/FCU/SCRIPTS/predictive_qc_lion_king/model_training/scripts/docker_app")
load("pc_app_data.RData")
AI_Assistant = dget("AI_Assistant_LK_app.R")
# basic_plots = dget("basic_plots.R")
# basic_statistics_exploratory_analysis = dget("basic_statistics_exploratory_analysis.R")
# histogram_exploratory_analysis = dget("histogram_exploratory_analysis.R")
# boxplot_exploratory_analysis = dget("boxplot_exploratory_analysis.R")
# CalculateAUC = dget("CalculateAUC.R")
# fastAUC = dget("fastAUC.R")
# plot_model_performance = dget("plot_model_performance.R")
# cut_off_distribution_table = dget("cut_off_distribution_table.R")
### DISPLAY DATA IN AI ASSITANT ###
AI_Assistant(dataset = dataset_fs,
stage = 'Model_results',
Variable_importance_all_methods = Variable_importance_all_methods_merged,
colnames_feature_selection = colnames_fs, #colnames(dataset_dummy_cat1), # colnames(dataset_dummy)
nn_results = nn_results1,
gbm_results = gbm_results1,
rf_results = rf_results1)
