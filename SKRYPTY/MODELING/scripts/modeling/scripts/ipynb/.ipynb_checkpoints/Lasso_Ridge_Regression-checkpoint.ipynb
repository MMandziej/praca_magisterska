{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "from random import randrange\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:/Users/mmandziej001/Desktop/FCU/SCRIPTS/predictive_qc_lion_king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452 44 0.03\n",
      "363 14 0.039\n"
     ]
    }
   ],
   "source": [
    "# load normalized train and test data\n",
    "train_data = pd.read_csv(r'model_training\\data\\PC\\dataset_dummy_grouped_time_train_cat8.csv')\n",
    "test_data = pd.read_csv(r'model_training\\data\\PC\\dataset_dummy_grouped_time_test_cat8.csv')\n",
    "print(len(train_data), sum(train_data['Label']), round(sum(train_data['Label']) / len(train_data), 3))\n",
    "print(len(test_data), sum(test_data['Label']), round(sum(test_data['Label']) / len(test_data), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TLAssignedName_Armannsson__G___Gabriela_', 'ScreenedParties', 'COFATCA/CRS_Major_last_10_checklists', 'PCFATCA/CRS_Major_last_5_checklists', 'CODocumentation_standard_Minor_last_5_checklists', 'COClient_Outreach_Major_last_5_checklists', 'PCDocumentation_standard_Major_last_10_checklists', 'DRClient_Outreach_Major_last_5_checklists', 'PCDocumentation_standard_Minor_last_10_checklists', 'PCDocumentation_standard_Major_last_5_checklists', 'PCDocumentation_standard_Minor_last_5_checklists', 'TeamExperience', 'PCFATCA/CRS_Critical_last_5_checklists', 'ProjectExperience', 'PCFATCA/CRS_Critical_last_10_checklists', 'DRClient_Outreach_Major_last_10_checklists', 'CRS_FALSE', 'CRS_TRUE', 'FATCA_FALSE', 'FATCA_TRUE']\n"
     ]
    }
   ],
   "source": [
    "# load features confirmed by boruta\n",
    "boruta_importance = pd.read_excel('model_training/data/ai_assistant_dumps/PC/8_FATCA_CRS/Boruta_variable_importance_pc.xlsx')\n",
    "boruta_importance = boruta_importance.sort_values(by=['normHits', 'meanImp'],\n",
    "                                                  ascending=True)\n",
    "boruta_features = list(\n",
    "    boruta_importance[boruta_importance['decision'] == 'Confirmed'].V7)\n",
    "boruta_pred_power = list(boruta_importance.V7)\n",
    "print(boruta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove technical and label columns\n",
    "train_id = train_data.pop('Unique')\n",
    "test_id = test_data.pop('Unique')\n",
    "\n",
    "train_labels = train_data.pop('Label')\n",
    "test_labels = test_data.pop('Label')\n",
    "\n",
    "train_datestamp = train_data.pop('datestamp')\n",
    "test_datestamp = test_data.pop('datestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing regularization path ...\n"
     ]
    }
   ],
   "source": [
    "### LOGISTIC REGRESSION - BEST MODEL SEARCH\n",
    "X_train = train_data[boruta_features]\n",
    "X_test = test_data[boruta_features]\n",
    "\n",
    "print(\"Computing regularization path ...\")\n",
    "C = [i/2 + 0.5 for i in range(1, 40, 1)]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: l1 C: 1.0 auc_train 0.8979129003099174 auc_test 0.8956201391731478\n",
      "Penalty: l1 C: 1.5 auc_train 0.8988329674586776 auc_test 0.8933688088415883\n",
      "Penalty: l1 C: 2.0 auc_train 0.8995351239669421 auc_test 0.8915268112975849\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d43a9cd5d82c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                                              1: pos_weight})\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mtrain_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mtest_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1358\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1361\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m         epsilon, sample_weight)\n\u001b[0m\u001b[0;32m    970\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for pen in ['l1', 'l2']:\n",
    "    for pos_weight, neg_weight in zip([0.9, 0.91, 0.92, 0.93], [0.1, 0.09, 0.08, 0.07]):\n",
    "        for c in C:\n",
    "            clf = linear_model.LogisticRegression(\n",
    "                penalty=pen, solver='liblinear', tol=1e-6, max_iter=int(1e6),\n",
    "                C=c, intercept_scaling=10000., class_weight={0: neg_weight,\n",
    "                                                             1: pos_weight})\n",
    "    \n",
    "            clf.fit(X_train, train_labels)\n",
    "            train_prob = clf.predict_proba(X_train)[:, 1]\n",
    "            test_prob = clf.predict_proba(X_test)[:, 1]\n",
    "            auc_train = roc_auc_score(train_labels, train_prob)\n",
    "            auc_test = roc_auc_score(test_labels, test_prob)\n",
    "            print('Penalty:', pen, 'C:', c, 'auc_train', auc_train, 'auc_test', auc_test)\n",
    "            if abs(auc_train - auc_test) < 0.015:\n",
    "                results.append({'model': pen,\n",
    "                                'penalty': c,\n",
    "                                'auc_train': auc_train,\n",
    "                                'auc_test': auc_test,\n",
    "                                'overfit': round(auc_train - auc_test, 3),\n",
    "                                'pos_weight': pos_weight,\n",
    "                                'neg_weight': neg_weight,\n",
    "                                'coefs': clf.coef_})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=['auc_train'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(results):\n",
    "    if i['auc_train'0.7669462316176471] > 0.765 and i['auc_test'] > 0.765:\n",
    "        print(idx, i['auc_train'], i['auc_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run best model\n",
    "coefs = {feature: coef for feature, coef in zip(\n",
    "    boruta_features, list(results_df.iloc[28,]['coefs'][0])) if coef != 0}\n",
    "\n",
    "best_model = linear_model.LogisticRegression(penalty='l1', solver='liblinear',\n",
    "                                      C=10, tol=1e-6, max_iter=int(1e6),\n",
    "                                      intercept_scaling=10000.,\n",
    "                                      class_weight={0: 0.08,\n",
    "                                                    1: 0.92})\n",
    "\n",
    "best_model.fit(X_train[coefs.keys()], train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob = best_model.predict_proba(X_train[coefs.keys()])[:,1]\n",
    "test_prob = best_model.predict_proba(X_test[coefs.keys()])[:,1]\n",
    "\n",
    "train_predictions_df = pd.DataFrame(train_prob)\n",
    "test_predictions_df = pd.DataFrame(test_prob)\n",
    "\n",
    "test_results = pd.concat([test_id, test_datestamp, test_predictions_df, test_labels], axis=1)\n",
    "test_results = test_results.rename(columns={0: \"Score\"})\n",
    "test_results = test_results.sort_values(by='Score', axis=0, ascending=False)\n",
    "\n",
    "SumTest = pd.DataFrame(np.cumsum(test_results['Label']))\n",
    "SumTest = SumTest.rename(columns={'Label': 'Sum'})\n",
    "test_results = pd.concat([test_results, SumTest], axis=1)\n",
    "test_results.reset_index(inplace=True, drop=True)\n",
    "X_coordinates = pd.DataFrame(np.arange(1, (test_results.shape[0]+1)) / (test_results.shape[0]))\n",
    "X_coordinates = X_coordinates.rename(columns={0: 'X_coordinates'})\n",
    "y_coordinates = pd.DataFrame(test_results['Sum']/test_results['Sum'].max())\n",
    "y_coordinates = y_coordinates.rename(columns={'Sum': 'y_coordinates'})\n",
    "test_results = pd.concat([test_results, X_coordinates, y_coordinates], axis=1)\n",
    "\n",
    "# train results\n",
    "train_results = pd.concat([train_id, train_datestamp, train_predictions_df, train_labels], axis=1)\n",
    "train_results = train_results.rename(columns={0: \"Score\"})\n",
    "train_results = train_results.sort_values(by='Score', axis=0, ascending=False)\n",
    "\n",
    "SumTrain = pd.DataFrame(np.cumsum(train_results['Label']))\n",
    "SumTrain = SumTrain.rename(columns={'Label': 'Sum'})\n",
    "train_results = pd.concat([train_results, SumTrain], axis=1)\n",
    "\n",
    "train_results.reset_index(inplace=True, drop=True)\n",
    "X_coordinates = pd.DataFrame(np.arange(1, (train_results.shape[0]+1))/(train_results.shape[0]))\n",
    "X_coordinates = X_coordinates.rename(columns={0: 'X_coordinates'})\n",
    "y_coordinates = pd.DataFrame(train_results['Sum']/train_results['Sum'].max())\n",
    "y_coordinates = y_coordinates.rename(columns={'Sum': 'y_coordinates'})\n",
    "train_results = pd.concat([train_results, X_coordinates, y_coordinates], axis=1)\n",
    "\n",
    "auc_test = roc_auc_score(test_labels, test_predictions_df)\n",
    "auc_train = roc_auc_score(train_labels, train_predictions_df)\n",
    "print(auc_train, auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(r'model_training\\results\\PC\\lr\\penalized_LR_results.xlsx')\n",
    "test_results.to_csv(r'model_training\\results\\PC\\lr\\lr_test_results.csv')\n",
    "train_results.to_csv(r'model_training\\results\\PC\\lr\\lr_train_results.csv')\n",
    "pickle.dump(best_model, open(r'model_training\\results\\PC\\penalized_LR_results.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
