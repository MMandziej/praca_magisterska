{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "from random import randrange\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:/Users/mmandziej001/Desktop/FCU/SCRIPTS/predictive_qc_lion_king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452 80 0.055\n",
      "363 20 0.055\n"
     ]
    }
   ],
   "source": [
    "# load normalized train and test data\n",
    "train_data = pd.read_csv(r'model_training\\data\\PC\\dataset_dummy_grouped_time_train_cat2.csv')\n",
    "test_data = pd.read_csv(r'model_training\\data\\PC\\dataset_dummy_grouped_time_test_cat2.csv')\n",
    "print(len(train_data), sum(train_data['Label']), round(sum(train_data['Label']) / len(train_data), 3))\n",
    "print(len(test_data), sum(test_data['Label']), round(sum(test_data['Label']) / len(test_data), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MLRORequest_TRUE', 'TLAssignedName_Kolodziejczyk__A___Anna_', 'PCRisk_factors_Critical_last_5_checklists', 'PartyType_Ultimate', 'PartyType_Subsidiary', 'CDDRiskLevel_Normal', 'OwnershipLayers', 'TLAssignedName_Bonczkowski__P___Pawel_', 'COClient_Outreach_Major_last_10_checklists', 'ProcessingUnit_MidCorp', 'PCRisk_factors_Major_last_10_checklists', 'CORelationship_Critical_last_5_checklists', 'DRRelationship_Major_last_5_checklists', 'PCDocumentation_standard_Major_last_5_checklists', 'PCESR_Major_last_10_checklists', 'PCDocumentation_standard_Major_last_10_checklists', 'GroupCases', 'DRDocumentation_standard_Minor_last_5_checklists', 'DRScreening_Major_last_10_checklists', 'TLAssignedName_Jurojc__M___Mateusz_', 'Category_BE_Nord', 'CDDRiskLevel_Low', 'PCRisk_factors_Critical_last_10_checklists', 'TLAssignedName_Yadav__N___Neha_', 'ProcessingCountry_BMG', 'PCRisk_factors_Minor_last_5_checklists', 'TLAssignedName_Michalik__J___Justyna_', 'PCDocumentation_standard_Minor_last_5_checklists', 'Category_BMG', 'COODD_(Office_Due_Diligence)_-_local_requirements_(if_applicable)_Major_last_10_checklists', 'PCScreening_Major_last_10_checklists', 'PCDocumentation_standard_Minor_last_10_checklists', 'PCRisk_factors_Major_last_5_checklists', 'CODocumentation_standard_Minor_last_5_checklists', 'CODocumentation_standard_Minor_last_10_checklists', 'ProjectExperience', 'TeamExperience', 'DRClient_Outreach_Major_last_5_checklists', 'DRClient_Outreach_Major_last_10_checklists', 'CDDRiskLevel_Increased']\n"
     ]
    }
   ],
   "source": [
    "# load features confirmed by boruta\n",
    "boruta_importance = pd.read_excel('model_training/data/ai_assistant_dumps/PC/2_Risk factors/Boruta_variable_importance_pc.xlsx')\n",
    "boruta_importance = boruta_importance.sort_values(by=['normHits', 'meanImp'],\n",
    "                                                  ascending=True)\n",
    "boruta_features = list(\n",
    "    boruta_importance[boruta_importance['decision'] == 'Confirmed'].V7)\n",
    "boruta_pred_power = list(boruta_importance.V7)\n",
    "print(boruta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove technical and label columns\n",
    "train_id = train_data.pop('Unique')\n",
    "test_id = test_data.pop('Unique')\n",
    "\n",
    "train_labels = train_data.pop('Label')\n",
    "test_labels = test_data.pop('Label')\n",
    "\n",
    "train_datestamp = train_data.pop('datestamp')\n",
    "test_datestamp = test_data.pop('datestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing regularization path ...\n"
     ]
    }
   ],
   "source": [
    "### LOGISTIC REGRESSION - BEST MODEL SEARCH\n",
    "X_train = train_data[boruta_features]\n",
    "X_test = test_data[boruta_features]\n",
    "\n",
    "print(\"Computing regularization path ...\")\n",
    "C = [i/2 + 0.5 for i in range(1, 40, 1)]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: l1 C: 1.0 auc_train 0.8418959548104956 auc_test 0.7728862973760933\n",
      "Penalty: l1 C: 1.5 auc_train 0.844519861516035 auc_test 0.7753644314868805\n",
      "Penalty: l1 C: 2.0 auc_train 0.8456222667638484 auc_test 0.7760932944606413\n",
      "Penalty: l1 C: 2.5 auc_train 0.8459684766763849 auc_test 0.777259475218659\n",
      "Penalty: l1 C: 3.0 auc_train 0.8485832725947522 auc_test 0.7794460641399417\n",
      "Penalty: l1 C: 3.5 auc_train 0.8503234329446064 auc_test 0.7800291545189505\n",
      "Penalty: l1 C: 4.0 auc_train 0.8514258381924199 auc_test 0.7800291545189504\n",
      "Penalty: l1 C: 4.5 auc_train 0.8519087099125364 auc_test 0.7800291545189504\n",
      "Penalty: l1 C: 5.0 auc_train 0.8522913629737608 auc_test 0.7801749271137026\n",
      "Penalty: l1 C: 5.5 auc_train 0.8525737973760933 auc_test 0.7811953352769679\n",
      "Penalty: l1 C: 6.0 auc_train 0.8526557944606414 auc_test 0.7806122448979592\n",
      "Penalty: l1 C: 6.5 auc_train 0.8527195699708455 auc_test 0.7811953352769679\n",
      "Penalty: l1 C: 7.0 auc_train 0.8529746720116618 auc_test 0.7816326530612245\n",
      "Penalty: l1 C: 7.5 auc_train 0.8530020043731779 auc_test 0.7817784256559767\n",
      "Penalty: l1 C: 8.0 auc_train 0.853065779883382 auc_test 0.7819241982507289\n",
      "Penalty: l1 C: 8.5 auc_train 0.853184220116618 auc_test 0.7819241982507289\n",
      "Penalty: l1 C: 9.0 auc_train 0.8531933309037901 auc_test 0.7819241982507288\n",
      "Penalty: l1 C: 9.5 auc_train 0.8532479956268222 auc_test 0.782069970845481\n",
      "Penalty: l1 C: 10.0 auc_train 0.8533299927113702 auc_test 0.7816326530612244\n",
      "Penalty: l1 C: 10.5 auc_train 0.8532662172011662 auc_test 0.7813411078717202\n",
      "Penalty: l1 C: 11.0 auc_train 0.8532935495626822 auc_test 0.7813411078717201\n",
      "Penalty: l1 C: 11.5 auc_train 0.8532844387755102 auc_test 0.7811953352769679\n",
      "Penalty: l1 C: 12.0 auc_train 0.8532388848396502 auc_test 0.7810495626822157\n",
      "Penalty: l1 C: 12.5 auc_train 0.8532662172011661 auc_test 0.7807580174927113\n",
      "Penalty: l1 C: 13.0 auc_train 0.8533482142857143 auc_test 0.7810495626822157\n",
      "Penalty: l1 C: 13.5 auc_train 0.8534575437317785 auc_test 0.7803206997084549\n",
      "Penalty: l1 C: 14.0 auc_train 0.8535668731778425 auc_test 0.780466472303207\n",
      "Penalty: l1 C: 14.5 auc_train 0.8536215379008746 auc_test 0.7801749271137026\n",
      "Penalty: l1 C: 15.0 auc_train 0.8537035349854227 auc_test 0.780466472303207\n",
      "Penalty: l1 C: 15.5 auc_train 0.8537035349854227 auc_test 0.7806122448979592\n",
      "Penalty: l1 C: 16.0 auc_train 0.853867529154519 auc_test 0.7806122448979591\n",
      "Penalty: l1 C: 16.5 auc_train 0.853940415451895 auc_test 0.7807580174927115\n",
      "Penalty: l1 C: 17.0 auc_train 0.8540952988338193 auc_test 0.7807580174927115\n",
      "Penalty: l1 C: 17.5 auc_train 0.8541590743440234 auc_test 0.7807580174927115\n",
      "Penalty: l1 C: 18.0 auc_train 0.8542319606413995 auc_test 0.7806122448979593\n",
      "Penalty: l1 C: 18.5 auc_train 0.8542501822157436 auc_test 0.780466472303207\n",
      "Penalty: l1 C: 19.0 auc_train 0.8542957361516035 auc_test 0.780466472303207\n",
      "Penalty: l1 C: 19.5 auc_train 0.8543959548104956 auc_test 0.7801749271137026\n",
      "Penalty: l1 C: 20.0 auc_train 0.8544050655976677 auc_test 0.7800291545189504\n",
      "Penalty: l1 C: 1.0 auc_train 0.8430530247813411 auc_test 0.7728862973760933\n",
      "Penalty: l1 C: 1.5 auc_train 0.8450391763848395 auc_test 0.7768221574344023\n",
      "Penalty: l1 C: 2.0 auc_train 0.846105138483965 auc_test 0.7766763848396503\n",
      "Penalty: l1 C: 2.5 auc_train 0.8468340014577259 auc_test 0.7782798833819242\n",
      "Penalty: l1 C: 3.0 auc_train 0.8492028061224489 auc_test 0.7793002915451895\n",
      "Penalty: l1 C: 3.5 auc_train 0.8512527332361516 auc_test 0.7788629737609329\n",
      "Penalty: l1 C: 4.0 auc_train 0.8520635932944607 auc_test 0.7801749271137026\n",
      "Penalty: l1 C: 4.5 auc_train 0.8527469023323615 auc_test 0.7811953352769679\n",
      "Penalty: l1 C: 5.0 auc_train 0.853175109329446 auc_test 0.7817784256559765\n",
      "Penalty: l1 C: 5.5 auc_train 0.8534028790087463 auc_test 0.782069970845481\n",
      "Penalty: l1 C: 6.0 auc_train 0.8535577623906706 auc_test 0.7822157434402331\n",
      "Penalty: l1 C: 6.5 auc_train 0.8536853134110787 auc_test 0.781924198250729\n",
      "Penalty: l1 C: 7.0 auc_train 0.8536762026239066 auc_test 0.7823615160349855\n",
      "Penalty: l1 C: 7.5 auc_train 0.8538401967930029 auc_test 0.7823615160349855\n",
      "Penalty: l1 C: 8.0 auc_train 0.8539768586005831 auc_test 0.7825072886297375\n",
      "Penalty: l1 C: 8.5 auc_train 0.8540588556851311 auc_test 0.7819241982507288\n",
      "Penalty: l1 C: 9.0 auc_train 0.8540952988338193 auc_test 0.7816326530612244\n",
      "Penalty: l1 C: 9.5 auc_train 0.8541044096209912 auc_test 0.7813411078717201\n",
      "Penalty: l1 C: 10.0 auc_train 0.8541317419825073 auc_test 0.7814868804664723\n",
      "Penalty: l1 C: 10.5 auc_train 0.8541499635568514 auc_test 0.7810495626822157\n",
      "Penalty: l1 C: 11.0 auc_train 0.8541681851311953 auc_test 0.7807580174927113\n",
      "Penalty: l1 C: 11.5 auc_train 0.8541772959183673 auc_test 0.7806122448979592\n",
      "Penalty: l1 C: 12.0 auc_train 0.8542410714285713 auc_test 0.7804664723032071\n",
      "Penalty: l1 C: 12.5 auc_train 0.8542684037900875 auc_test 0.7803206997084549\n",
      "Penalty: l1 C: 13.0 auc_train 0.8542319606413994 auc_test 0.780466472303207\n",
      "Penalty: l1 C: 13.5 auc_train 0.8542319606413995 auc_test 0.780466472303207\n",
      "Penalty: l1 C: 14.0 auc_train 0.8542501822157434 auc_test 0.7803206997084549\n",
      "Penalty: l1 C: 14.5 auc_train 0.8543321793002915 auc_test 0.7803206997084549\n",
      "Penalty: l1 C: 15.0 auc_train 0.8543777332361516 auc_test 0.7803206997084549\n",
      "Penalty: l1 C: 15.5 auc_train 0.8545052842565597 auc_test 0.7800291545189504\n",
      "Penalty: l1 C: 16.0 auc_train 0.854632835276968 auc_test 0.7801749271137026\n",
      "Penalty: l1 C: 16.5 auc_train 0.8546328352769679 auc_test 0.7801749271137026\n",
      "Penalty: l1 C: 17.0 auc_train 0.8546874999999999 auc_test 0.7800291545189504\n",
      "Penalty: l1 C: 17.5 auc_train 0.8547786078717201 auc_test 0.7801749271137026\n",
      "Penalty: l1 C: 18.0 auc_train 0.8548150510204081 auc_test 0.7803206997084549\n",
      "Penalty: l1 C: 18.5 auc_train 0.8548514941690962 auc_test 0.7800291545189504\n",
      "Penalty: l1 C: 19.0 auc_train 0.8548514941690962 auc_test 0.7798833819241981\n",
      "Penalty: l1 C: 19.5 auc_train 0.8548423833819241 auc_test 0.7797376093294461\n",
      "Penalty: l1 C: 20.0 auc_train 0.8549334912536444 auc_test 0.7797376093294461\n",
      "Penalty: l1 C: 1.0 auc_train 0.8433354591836734 auc_test 0.7733236151603499\n",
      "Penalty: l1 C: 1.5 auc_train 0.8460231413994168 auc_test 0.7772594752186589\n",
      "Penalty: l1 C: 2.0 auc_train 0.8468795553935862 auc_test 0.7776967930029155\n",
      "Penalty: l1 C: 2.5 auc_train 0.8472804300291545 auc_test 0.7791545189504373\n",
      "Penalty: l1 C: 3.0 auc_train 0.8493212463556851 auc_test 0.7793002915451895\n",
      "Penalty: l1 C: 3.5 auc_train 0.8513438411078718 auc_test 0.7803206997084549\n",
      "Penalty: l1 C: 4.0 auc_train 0.8524098032069971 auc_test 0.7813411078717202\n",
      "Penalty: l1 C: 4.5 auc_train 0.8530931122448979 auc_test 0.7807580174927113\n",
      "Penalty: l1 C: 5.0 auc_train 0.8535213192419825 auc_test 0.7814868804664723\n",
      "Penalty: l1 C: 5.5 auc_train 0.8536579810495626 auc_test 0.7819241982507288\n",
      "Penalty: l1 C: 6.0 auc_train 0.8540406341107871 auc_test 0.7819241982507288\n",
      "Penalty: l1 C: 6.5 auc_train 0.8541772959183674 auc_test 0.7816326530612244\n",
      "Penalty: l1 C: 7.0 auc_train 0.8542137390670553 auc_test 0.7813411078717201\n",
      "Penalty: l1 C: 7.5 auc_train 0.8543139577259475 auc_test 0.7806122448979591\n",
      "Penalty: l1 C: 8.0 auc_train 0.8544141763848396 auc_test 0.7809037900874636\n",
      "Penalty: l1 C: 8.5 auc_train 0.8544050655976676 auc_test 0.7807580174927113\n",
      "Penalty: l1 C: 9.0 auc_train 0.8545417274052478 auc_test 0.7807580174927113\n",
      "Penalty: l1 C: 9.5 auc_train 0.8546055029154519 auc_test 0.7806122448979591\n",
      "Penalty: l1 C: 10.0 auc_train 0.8546510568513119 auc_test 0.780466472303207\n",
      "Penalty: l1 C: 10.5 auc_train 0.8546966107871721 auc_test 0.7809037900874636\n",
      "Penalty: l1 C: 11.0 auc_train 0.854723943148688 auc_test 0.7813411078717201\n",
      "Penalty: l1 C: 11.5 auc_train 0.8547694970845481 auc_test 0.7814868804664723\n",
      "Penalty: l1 C: 12.0 auc_train 0.854760386297376 auc_test 0.7813411078717201\n",
      "Penalty: l1 C: 12.5 auc_train 0.8548606049562681 auc_test 0.7807580174927113\n",
      "Penalty: l1 C: 13.0 auc_train 0.8548970481049564 auc_test 0.7810495626822158\n",
      "Penalty: l1 C: 13.5 auc_train 0.8549426020408162 auc_test 0.7809037900874636\n",
      "Penalty: l1 C: 14.0 auc_train 0.8549517128279884 auc_test 0.7809037900874637\n",
      "Penalty: l1 C: 14.5 auc_train 0.8549608236151602 auc_test 0.7809037900874636\n",
      "Penalty: l1 C: 15.0 auc_train 0.8549517128279884 auc_test 0.7809037900874636\n",
      "Penalty: l1 C: 15.5 auc_train 0.8550245991253644 auc_test 0.7806122448979591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: l1 C: 16.0 auc_train 0.8550519314868805 auc_test 0.7804664723032071\n",
      "Penalty: l1 C: 16.5 auc_train 0.8551157069970845 auc_test 0.7803206997084549\n",
      "Penalty: l1 C: 17.0 auc_train 0.8551521501457726 auc_test 0.7801749271137026\n",
      "Penalty: l1 C: 17.5 auc_train 0.8551703717201167 auc_test 0.7801749271137026\n",
      "Penalty: l1 C: 18.0 auc_train 0.8552432580174928 auc_test 0.7798833819241983\n",
      "Penalty: l1 C: 18.5 auc_train 0.8553525874635568 auc_test 0.7800291545189504\n",
      "Penalty: l1 C: 19.0 auc_train 0.855407252186589 auc_test 0.7798833819241983\n",
      "Penalty: l1 C: 19.5 auc_train 0.8554710276967931 auc_test 0.7798833819241984\n",
      "Penalty: l1 C: 20.0 auc_train 0.855498360058309 auc_test 0.7797376093294461\n",
      "Penalty: l1 C: 1.0 auc_train 0.8435814504373178 auc_test 0.7739067055393587\n",
      "Penalty: l1 C: 1.5 auc_train 0.8467246720116618 auc_test 0.7785714285714287\n",
      "Penalty: l1 C: 2.0 auc_train 0.8477633017492712 auc_test 0.7785714285714286\n",
      "Penalty: l1 C: 2.5 auc_train 0.8483828352769679 auc_test 0.7798833819241983\n",
      "Penalty: l1 C: 3.0 auc_train 0.8496036807580175 auc_test 0.7809037900874636\n",
      "Penalty: l1 C: 3.5 auc_train 0.8515351676384839 auc_test 0.7819241982507289\n",
      "Penalty: l1 C: 4.0 auc_train 0.8526466836734695 auc_test 0.7819241982507289\n",
      "Penalty: l1 C: 4.5 auc_train 0.8536944241982507 auc_test 0.7822157434402333\n",
      "Penalty: l1 C: 5.0 auc_train 0.8541226311953354 auc_test 0.7822157434402333\n",
      "Penalty: l1 C: 5.5 auc_train 0.8542866253644315 auc_test 0.7814868804664723\n",
      "Penalty: l1 C: 6.0 auc_train 0.8544506195335276 auc_test 0.7817784256559767\n",
      "Penalty: l1 C: 6.5 auc_train 0.8545690597667638 auc_test 0.7817784256559767\n",
      "Penalty: l1 C: 7.0 auc_train 0.8547239431486882 auc_test 0.7823615160349855\n",
      "Penalty: l1 C: 7.5 auc_train 0.8549152696793003 auc_test 0.7817784256559767\n",
      "Penalty: l1 C: 8.0 auc_train 0.8550519314868804 auc_test 0.7814868804664723\n",
      "Penalty: l1 C: 8.5 auc_train 0.8551521501457727 auc_test 0.7816326530612245\n",
      "Penalty: l1 C: 9.0 auc_train 0.8551430393586006 auc_test 0.7811953352769679\n",
      "Penalty: l1 C: 9.5 auc_train 0.8551612609329446 auc_test 0.7811953352769679\n",
      "Penalty: l1 C: 10.0 auc_train 0.8551157069970845 auc_test 0.7809037900874636\n",
      "Penalty: l1 C: 10.5 auc_train 0.8551794825072886 auc_test 0.7810495626822158\n",
      "Penalty: l1 C: 11.0 auc_train 0.8553070335276968 auc_test 0.7811953352769679\n",
      "Penalty: l1 C: 11.5 auc_train 0.8553161443148688 auc_test 0.7809037900874636\n",
      "Penalty: l1 C: 12.0 auc_train 0.8553525874635568 auc_test 0.7809037900874636\n",
      "Penalty: l1 C: 12.5 auc_train 0.8553525874635568 auc_test 0.7807580174927113\n",
      "Penalty: l1 C: 13.0 auc_train 0.8553708090379009 auc_test 0.7807580174927113\n",
      "Penalty: l1 C: 13.5 auc_train 0.855398141399417 auc_test 0.7806122448979593\n",
      "Penalty: l1 C: 14.0 auc_train 0.8554254737609329 auc_test 0.7803206997084549\n",
      "Penalty: l1 C: 14.5 auc_train 0.855407252186589 auc_test 0.7807580174927115\n",
      "Penalty: l1 C: 15.0 auc_train 0.8555621355685131 auc_test 0.781195335276968\n",
      "Penalty: l1 C: 15.5 auc_train 0.8555530247813412 auc_test 0.781195335276968\n",
      "Penalty: l1 C: 16.0 auc_train 0.855571246355685 auc_test 0.7810495626822158\n",
      "Penalty: l1 C: 16.5 auc_train 0.8555894679300291 auc_test 0.781195335276968\n",
      "Penalty: l1 C: 17.0 auc_train 0.8555894679300291 auc_test 0.7810495626822158\n",
      "Penalty: l1 C: 17.5 auc_train 0.8556532434402332 auc_test 0.7806122448979592\n",
      "Penalty: l1 C: 18.0 auc_train 0.8557625728862974 auc_test 0.7806122448979592\n",
      "Penalty: l1 C: 18.5 auc_train 0.8558172376093294 auc_test 0.7803206997084549\n",
      "Penalty: l1 C: 19.0 auc_train 0.8558445699708455 auc_test 0.7804664723032071\n",
      "Penalty: l1 C: 19.5 auc_train 0.8559083454810495 auc_test 0.7804664723032071\n",
      "Penalty: l1 C: 20.0 auc_train 0.8559630102040816 auc_test 0.7804664723032071\n",
      "Penalty: l1 C: 1.0 auc_train 0.8436270043731778 auc_test 0.773469387755102\n",
      "Penalty: l1 C: 1.5 auc_train 0.8471893221574344 auc_test 0.7785714285714286\n",
      "Penalty: l1 C: 2.0 auc_train 0.8479637390670555 auc_test 0.7800291545189504\n"
     ]
    }
   ],
   "source": [
    "for pen in ['l1', 'l2']:\n",
    "    for pos_weight, neg_weight in zip([0.9, 0.91, 0.92, 0.93, 0.94, 0.95], [0.1, 0.09, 0.08, 0.07, 0.06, 0.05]):\n",
    "        for c in C:\n",
    "            clf = linear_model.LogisticRegression(\n",
    "                penalty=pen, solver='liblinear', tol=1e-6, max_iter=int(1e6),\n",
    "                C=c, intercept_scaling=10000., class_weight={0: neg_weight,\n",
    "                                                             1: pos_weight})\n",
    "    \n",
    "            clf.fit(X_train, train_labels)\n",
    "            train_prob = clf.predict_proba(X_train)[:, 1]\n",
    "            test_prob = clf.predict_proba(X_test)[:, 1]\n",
    "            auc_train = roc_auc_score(train_labels, train_prob)\n",
    "            auc_test = roc_auc_score(test_labels, test_prob)\n",
    "            print('Penalty:', pen, 'C:', c, 'Pos_weight:', pos_weight, 'auc_train', round(auc_train, 3), 'auc_test', round(auc_test, 3))\n",
    "            if abs(auc_train - auc_test) < 0.015:\n",
    "                results.append({'model': pen,\n",
    "                                'penalty': c,\n",
    "                                'auc_train': auc_train,\n",
    "                                'auc_test': auc_test,\n",
    "                                'overfit': round(auc_train - auc_test, 3),\n",
    "                                'pos_weight': pos_weight,\n",
    "                                'neg_weight': neg_weight,\n",
    "                                'coefs': clf.coef_})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=['auc_train'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(results):\n",
    "    if i['auc_train'0.7669462316176471] > 0.765 and i['auc_test'] > 0.765:\n",
    "        print(idx, i['auc_train'], i['auc_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run best model\n",
    "coefs = {feature: coef for feature, coef in zip(\n",
    "    boruta_features, list(results_df.iloc[28,]['coefs'][0])) if coef != 0}\n",
    "\n",
    "best_model = linear_model.LogisticRegression(penalty='l1', solver='liblinear',\n",
    "                                      C=10, tol=1e-6, max_iter=int(1e6),\n",
    "                                      intercept_scaling=10000.,\n",
    "                                      class_weight={0: 0.08,\n",
    "                                                    1: 0.92})\n",
    "\n",
    "best_model.fit(X_train[coefs.keys()], train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob = best_model.predict_proba(X_train[coefs.keys()])[:,1]\n",
    "test_prob = best_model.predict_proba(X_test[coefs.keys()])[:,1]\n",
    "\n",
    "train_predictions_df = pd.DataFrame(train_prob)\n",
    "test_predictions_df = pd.DataFrame(test_prob)\n",
    "\n",
    "test_results = pd.concat([test_id, test_datestamp, test_predictions_df, test_labels], axis=1)\n",
    "test_results = test_results.rename(columns={0: \"Score\"})\n",
    "test_results = test_results.sort_values(by='Score', axis=0, ascending=False)\n",
    "\n",
    "SumTest = pd.DataFrame(np.cumsum(test_results['Label']))\n",
    "SumTest = SumTest.rename(columns={'Label': 'Sum'})\n",
    "test_results = pd.concat([test_results, SumTest], axis=1)\n",
    "test_results.reset_index(inplace=True, drop=True)\n",
    "X_coordinates = pd.DataFrame(np.arange(1, (test_results.shape[0]+1)) / (test_results.shape[0]))\n",
    "X_coordinates = X_coordinates.rename(columns={0: 'X_coordinates'})\n",
    "y_coordinates = pd.DataFrame(test_results['Sum']/test_results['Sum'].max())\n",
    "y_coordinates = y_coordinates.rename(columns={'Sum': 'y_coordinates'})\n",
    "test_results = pd.concat([test_results, X_coordinates, y_coordinates], axis=1)\n",
    "\n",
    "# train results\n",
    "train_results = pd.concat([train_id, train_datestamp, train_predictions_df, train_labels], axis=1)\n",
    "train_results = train_results.rename(columns={0: \"Score\"})\n",
    "train_results = train_results.sort_values(by='Score', axis=0, ascending=False)\n",
    "\n",
    "SumTrain = pd.DataFrame(np.cumsum(train_results['Label']))\n",
    "SumTrain = SumTrain.rename(columns={'Label': 'Sum'})\n",
    "train_results = pd.concat([train_results, SumTrain], axis=1)\n",
    "\n",
    "train_results.reset_index(inplace=True, drop=True)\n",
    "X_coordinates = pd.DataFrame(np.arange(1, (train_results.shape[0]+1))/(train_results.shape[0]))\n",
    "X_coordinates = X_coordinates.rename(columns={0: 'X_coordinates'})\n",
    "y_coordinates = pd.DataFrame(train_results['Sum']/train_results['Sum'].max())\n",
    "y_coordinates = y_coordinates.rename(columns={'Sum': 'y_coordinates'})\n",
    "train_results = pd.concat([train_results, X_coordinates, y_coordinates], axis=1)\n",
    "\n",
    "auc_test = roc_auc_score(test_labels, test_predictions_df)\n",
    "auc_train = roc_auc_score(train_labels, train_predictions_df)\n",
    "print(auc_train, auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(r'model_training\\results\\PC\\lr\\penalized_LR_results.xlsx')\n",
    "test_results.to_csv(r'model_training\\results\\PC\\lr\\lr_test_results.csv')\n",
    "train_results.to_csv(r'model_training\\results\\PC\\lr\\lr_train_results.csv')\n",
    "pickle.dump(best_model, open(r'model_training\\results\\PC\\penalized_LR_results.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
