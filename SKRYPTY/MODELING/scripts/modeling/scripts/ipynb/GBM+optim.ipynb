{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------                      GBM                      ----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from imxgboost.imbalance_xgb import imbalance_xgboost as imb_xgb\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:/Users/mmandziej001/Desktop/Projects/FAIT/Prediction Module/POLAND_DANE/MODELING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('model_training/data/data_train_under_inputed.csv')\n",
    "test_data = pd.read_csv('model_training/data/data_test_under_inputed.csv')\n",
    "\n",
    "train_id = train_data.pop('NIP')\n",
    "test_id = test_data.pop('NIP')\n",
    "\n",
    "train_labels = train_data.pop('Label')\n",
    "test_labels = test_data.pop('Label')\n",
    "\n",
    "train_datestamp = train_data.pop('DataUpadlosci')\n",
    "test_datestamp = test_data.pop('DataUpadlosci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boruta_features = ['ScreenedParties', 'PartyType_Subsidiary', 'Critical_last_3_checklistsDR', 'ESR_Full_ESR_review', 'Minor_last_3_checklistsDR', 'Minor_last_3_checklistsPC', 'Major_last_3_checklistsPC', 'TLAssignedName_Yadav__N___Neha_', 'Cases_last_30_days_of_PC', 'Minor_last_10_checklistsDR', 'Critical_last_10_checklistsDR', 'Cases_last_5_days_of_PC', 'TLAssignedName_Makowska__M_M___Malgorzata_', 'TLAssignedName_Michalik__J___Justyna_', 'TeamExperience', 'HourNumeric', 'GroupCases', 'TLAssignedName_Jurojc__M___Mateusz_', 'ProcessingUnit_Gdansk', 'ProcessingUnit_MidCorp', 'FirstGroupCase', 'TLAssignedName_Jastrzebowska__S___Sonia_', 'Minor_last_10_checklistsPC', 'Major_last_10_checklistsPC', 'TLAssignedName_Marcos_Cantabrana__I___Ivan_', 'TLAssignedName_Wojciechowska__M___Magdalena_', 'ProjectExperience', 'Cases_last_30_days_of_DR', 'Cases_last_5_days_of_DR', 'TLAssignedName_Rybka__I_A___Izabela_Anna_', 'Major_last_10_checklistsDR', 'Major_last_3_checklistsDR', 'Major_last_5_checklistsDR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_importance = pd.read_excel('model_training/R_DUMPS/Boruta_variable_importance_under.xlsx')\n",
    "boruta_importance = boruta_importance.sort_values(by=['normHits', 'meanImp'],\n",
    "                                                  ascending=True)\n",
    "boruta_features = list(\n",
    "    boruta_importance[boruta_importance['decision'] == 'Confirmed'].V7)\n",
    "boruta_pred_power = list(boruta_importance.V7)\n",
    "boruta_features = [c for c in boruta_features if c not in [\n",
    "    'DeclaredAccountsCount', 'RemovalDaysAgo',\n",
    "    'X6', 'RevenueToCash', 'P4', 'RevenueToWages']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[boruta_features] # used_columns, boruta_features\n",
    "train_data = train_data[boruta_features] # used_columns, boruta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EMISLegalForm_Other', 'ExpiredLicenses', 'ActiveLicenses', 'NoMail_NIE', 'FormaWlasnosci_WŁASNOŚĆ PRYWATNA KRAJOWA POZOSTAŁA', 'FormaWlasnosci_WŁASNOŚĆ ZAGRANICZNA', 'VirtualAccountsPresence_NIE', 'NoMail_TAK', 'PhoneNotPresent_NIE', 'PhoneNotPresent_TAK', 'FormaWlasnosci_Other', 'FormaWlasnosci_WŁASNOŚĆ KRAJOWYCH OSÓB FIZYCZNYCH', 'SpecialLegalForm_SPÓŁKI JAWNE', 'VirtualAccountsPresence_TAK', 'AdresBiuroWirtualne_NIE', 'RyzykownaDziałalnoscGlowna_NIE', 'AdresLokal_TAK', 'NoFax_TAK', 'NoFax_NIE', 'CAACEksport_NIE', 'NoWebsite_NIE', 'NoWebsite_TAK', 'AdresLokal_NIE', 'CAACImport_NIE', 'AffiliatesCount', 'DescriptionNull_NIE', 'AdresLokal_BrakDanych', 'DescriptionNull_TAK', 'MainPKD_BrakDanych', 'CAACImport_BrakDanych', 'CAACEksport_BrakDanych', 'RyzykowneDzialalnosciDodatkowe_BrakDanych', 'RyzykownaDziałalnoscGlowna_BrakDanych', 'AdresBiuroWirtualne_BrakDanych', 'NonCurrentLiabilities', 'ExternalIdsOthers', 'EMISLegalForm_PL-SK', 'RepresentationCount', 'RetainedEarnings', 'CashandCashEquivalents', 'SpecialLegalForm_SPÓŁKI AKCYJNE', 'EMISLegalForm_PL-SJ', 'TotalAssets', 'ProfitBeforeIncomeTax', 'ROE', 'PropertyPlantAndEquipment', 'OperatingProfitEBIT', 'X10', 'TotalLiabilities', 'RyzykowneDzialalnosciDodatkowe_TAK', 'NetProfitLossForThePeriod', 'EMISLegalForm_PL-SA', 'DepreciationAmortization', 'X14', 'CurrentAssets', 'A3', 'A2', 'IncomeTax', 'RegisteredCapitalValue', 'NumberOfEmployees', 'CurrentLiabilities', 'PreviousNamesCount', 'ROA', 'WorkingCapital', 'SpecialLegalForm_SPÓŁKI KOMANDYTOWE', 'X11', 'X8', 'EMISLegalForm_PL-SPZOO', 'LegalForm_JEDNOSTKA ORGANIZACYJNA NIEMAJĄCA OSOBOWOŚCI PRAWNEJ', 'A4', 'BruttoMargin', 'ROS', 'LegalForm_OSOBA PRAWNA', 'DepreciationImpairment', 'X13', 'X9', 'SpecialLegalForm_SPÓŁKI Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ', 'EmployeeBenefitExpense', 'IssuedCapital', 'A5', 'PreviousNameChangeYearsAgo', 'TotalEquity', 'NetSalesRevenue', 'RyzykowneDzialalnosciDodatkowe_NIE', 'A1', 'P3', 'ExecutivesCount', 'AuditDaysAgo', 'Wiek', 'SecondaryPKDCount', 'OwnersCount']\n",
      "41752 14988 0.36\n",
      "10438 3747 0.36\n"
     ]
    }
   ],
   "source": [
    "print(list(train_data))\n",
    "print(len(train_labels), sum(train_labels), round(sum(train_labels)/len(train_labels), 2))\n",
    "print(len(test_labels), sum(test_labels), round(sum(test_labels)/len(test_labels), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.array(train_data)\n",
    "test_features = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_GBM = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in range(60, 125, 10):\n",
    "    for ne in range(13000, 22000, 1000):\n",
    "        model = lgb.LGBMClassifier(max_depth=1, learning_rate=lr/100000, n_estimators=ne, is_unbalance=True)#,is_unbalance=True\n",
    "        model.fit(train_data, train_labels)\n",
    "        test_predictions = model.predict_proba(test_data, raw_score=True)\n",
    "        train_predictions = model.predict_proba(train_data, raw_score=True)\n",
    "        auc_test = roc_auc_score(test_labels, test_predictions)\n",
    "        auc_train = roc_auc_score(train_labels, train_predictions)\n",
    "        overfit = round(auc_train - auc_test, 4)\n",
    "        results_GBM.append({'max_depth': 1,\n",
    "                            'learning_rate': lr/100000,\n",
    "                            'n_estimators': ne, \n",
    "                            'auc_train': auc_train,\n",
    "                            'auc_test': auc_test,\n",
    "                            'overfit': overfit})\n",
    "        print('Learning rate:', lr/10000, 'N estimators:', ne, 'AUC train:',\n",
    "              round(auc_train, 3), 'AUC test:', round(auc_test, 3), 'Overfit:', overfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic model - baseline for auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC train: 0.932 AUC test: 0.93 Overfit: 0.0022\n"
     ]
    }
   ],
   "source": [
    "# save default parameters\n",
    "# model = lgb.LGBMClassifier(max_depth=1, learning_rate=0.001 , n_estimators=15000)#,is_unbalance=True\n",
    "# model = lgb.LGBMClassifier(max_depth=1, learning_rate=0.0006 , n_estimators=13200)#,is_unbalance=True\n",
    "\n",
    "model = lgb.LGBMClassifier(max_depth=1, learning_rate=0.001, n_estimators=15000) #,is_unbalance=True)\n",
    "model.fit(train_data, train_labels)\n",
    "# train_time = timer() - start\n",
    "test_predictions = model.predict_proba(test_data, raw_score=True)\n",
    "train_predictions = model.predict_proba(train_data, raw_score=True)\n",
    "auc_test = roc_auc_score(test_labels, test_predictions)\n",
    "auc_train = roc_auc_score(train_labels, train_predictions)\n",
    "overfit = round(auc_train - auc_test, 4)\n",
    "print('AUC train:', round(auc_train, 3), 'AUC test:', round(auc_test, 3), 'Overfit:', overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_GBM)\n",
    "results_df.to_excel(r'model_training\\results\\PC\\gbm\\gbm_cat_all_boruta.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_df = pd.DataFrame(test_predictions)\n",
    "train_predictions_df = pd.DataFrame(train_predictions)\n",
    "\n",
    "test_results = pd.concat([test_id, test_datestamp, test_predictions_df, test_labels], axis=1)\n",
    "test_results = test_results.rename(columns={0: \"Score\"})\n",
    "test_results = test_results.sort_values(by='Score', axis=0, ascending=False)\n",
    "\n",
    "SumTest = pd.DataFrame(np.cumsum(test_results['Label']))\n",
    "SumTest = SumTest.rename(columns={'Label': 'Sum'})\n",
    "test_results = pd.concat([test_results, SumTest], axis=1)\n",
    "test_results.reset_index(inplace = True , drop=True)\n",
    "X_coordinates = pd.DataFrame(np.arange(1,(test_results.shape[0]+1))/(test_results.shape[0]))\n",
    "X_coordinates = X_coordinates.rename(columns={0: 'X_coordinates'})\n",
    "y_coordinates = pd.DataFrame(test_results['Sum']/test_results['Sum'].max())\n",
    "y_coordinates = y_coordinates.rename(columns={'Sum': 'y_coordinates'})\n",
    "test_results = pd.concat([test_results, X_coordinates,y_coordinates], axis=1)\n",
    "\n",
    "# train results\n",
    "train_results = pd.concat([train_id, train_datestamp, train_predictions_df, train_labels], axis=1)\n",
    "train_results = train_results.rename(columns={0:\"Score\"})\n",
    "train_results = train_results.sort_values(by='Score', axis=0, ascending=False)\n",
    "\n",
    "SumTrain = pd.DataFrame(np.cumsum(train_results['Label']))\n",
    "SumTrain = SumTrain.rename(columns={'Label':'Sum'})\n",
    "train_results = pd.concat([train_results, SumTrain], axis=1)\n",
    "\n",
    "train_results.reset_index(inplace = True , drop=True)\n",
    "X_coordinates = pd.DataFrame(np.arange(1,(train_results.shape[0]+1))/(train_results.shape[0]))\n",
    "X_coordinates = X_coordinates.rename(columns={0: 'X_coordinates'})\n",
    "y_coordinates = pd.DataFrame(train_results['Sum']/train_results['Sum'].max())\n",
    "y_coordinates = y_coordinates.rename(columns={'Sum': 'y_coordinates'})\n",
    "train_results = pd.concat([train_results, X_coordinates,y_coordinates], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EMISLegalForm_Other', 'ExpiredLicenses', 'ActiveLicenses', 'NoMail_NIE', 'FormaWlasnosci_WŁASNOŚĆ PRYWATNA KRAJOWA POZOSTAŁA', 'FormaWlasnosci_WŁASNOŚĆ ZAGRANICZNA', 'VirtualAccountsPresence_NIE', 'NoMail_TAK', 'PhoneNotPresent_NIE', 'PhoneNotPresent_TAK', 'FormaWlasnosci_Other', 'FormaWlasnosci_WŁASNOŚĆ KRAJOWYCH OSÓB FIZYCZNYCH', 'SpecialLegalForm_SPÓŁKI JAWNE', 'VirtualAccountsPresence_TAK', 'AdresBiuroWirtualne_NIE', 'RyzykownaDziałalnoscGlowna_NIE', 'AdresLokal_TAK', 'NoFax_TAK', 'NoFax_NIE', 'CAACEksport_NIE', 'NoWebsite_NIE', 'NoWebsite_TAK', 'AdresLokal_NIE', 'CAACImport_NIE', 'AffiliatesCount', 'DescriptionNull_NIE', 'AdresLokal_BrakDanych', 'DescriptionNull_TAK', 'MainPKD_BrakDanych', 'CAACImport_BrakDanych', 'CAACEksport_BrakDanych', 'RyzykowneDzialalnosciDodatkowe_BrakDanych', 'RyzykownaDziałalnoscGlowna_BrakDanych', 'AdresBiuroWirtualne_BrakDanych', 'NonCurrentLiabilities', 'ExternalIdsOthers', 'EMISLegalForm_PL-SK', 'RepresentationCount', 'RetainedEarnings', 'CashandCashEquivalents', 'SpecialLegalForm_SPÓŁKI AKCYJNE', 'EMISLegalForm_PL-SJ', 'TotalAssets', 'ProfitBeforeIncomeTax', 'ROE', 'PropertyPlantAndEquipment', 'OperatingProfitEBIT', 'X10', 'TotalLiabilities', 'RyzykowneDzialalnosciDodatkowe_TAK', 'NetProfitLossForThePeriod', 'EMISLegalForm_PL-SA', 'DepreciationAmortization', 'X14', 'CurrentAssets', 'A3', 'A2', 'IncomeTax', 'RegisteredCapitalValue', 'NumberOfEmployees', 'CurrentLiabilities', 'PreviousNamesCount', 'ROA', 'WorkingCapital', 'SpecialLegalForm_SPÓŁKI KOMANDYTOWE', 'X11', 'X8', 'EMISLegalForm_PL-SPZOO', 'LegalForm_JEDNOSTKA ORGANIZACYJNA NIEMAJĄCA OSOBOWOŚCI PRAWNEJ', 'A4', 'BruttoMargin', 'ROS', 'LegalForm_OSOBA PRAWNA', 'DepreciationImpairment', 'X13', 'X9', 'SpecialLegalForm_SPÓŁKI Z OGRANICZONĄ ODPOWIEDZIALNOŚCIĄ', 'EmployeeBenefitExpense', 'IssuedCapital', 'A5', 'PreviousNameChangeYearsAgo', 'TotalEquity', 'NetSalesRevenue', 'RyzykowneDzialalnosciDodatkowe_NIE', 'A1', 'P3', 'ExecutivesCount', 'AuditDaysAgo', 'Wiek', 'SecondaryPKDCount', 'OwnersCount']\n"
     ]
    }
   ],
   "source": [
    "test_results.to_csv(r'model_training/results/gbm/gbm_test_results.csv')\n",
    "train_results.to_csv(r'model_training/results/gbm/gbm_train_results.csv')\n",
    "model.booster_.save_model(r'model_training/results/gbm/gbm_best_model.txt')\n",
    "#model = lgb.Booster(model_file=r'gbm_best_model.txt')\n",
    "print(list(train_data.columns))\n",
    "with open('model_training/results/gbm/used_features.txt', 'w') as f:\n",
    "    for item in train_data.columns:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian hyperoptimalization - has a tendency to overfit, therefore watch out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "N_FOLDS=3\n",
    "\n",
    "\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Retrieve the subsample if present otherwise set to 1.0\n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type\n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(params, lgb.Dataset(train_data,train_labels), num_boost_round = 10000, nfold = n_folds, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = np.max(cv_results['auc-mean'])\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, params, ITERATION, n_estimators, run_time])\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
    "            'estimators': n_estimators, \n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the learning rate\n",
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.5))}\n",
    "num_leaves = {'num_leaves': hp.quniform('num_leaves', 20, 250, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_type = {'boosting_type': hp.choice('boosting_type', \n",
    "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n",
    "                                             {'boosting_type': 'dart', 'subsample': hp.uniform('subsample', 0.5, 1)},\n",
    "                                             {'boosting_type': 'goss', 'subsample': 1.0}])}\n",
    "# Draw a sample\n",
    "params = sample(boosting_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "\n",
    "# Extract the boosting type\n",
    "params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "params['subsample'] = subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'max_depth' : hp.choice('max_depth',np.arange(1, 14, dtype=int)),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_algorithm = tpe.suggest\n",
    "bayes_trials = Trials()\n",
    "\n",
    "out_file = 'gbm_trials.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 10\n",
    "MAX_EVALS=50\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 0.7292016631698011,\n",
       " 'learning_rate': 0.010705097915397449,\n",
       " 'min_child_samples': 20,\n",
       " 'num_leaves': 39,\n",
       " 'reg_alpha': 0.6689164372874457,\n",
       " 'reg_lambda': 0.5471632266906857,\n",
       " 'subsample_for_bin': 100000,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "#bayes_trials_results = sorted(bayes_trials.results, key = lambda x: x['loss'])\n",
    "results = pd.read_csv('gbm_trials.csv')\n",
    "\n",
    "# Sort with best scores on top and reset index for slicing\n",
    "results.sort_values('loss', ascending = True, inplace = True)\n",
    "results.reset_index(inplace = True, drop = True)\n",
    "results.head()\n",
    "\n",
    "\n",
    "# Convert from a string to a dictionary\n",
    "ast.literal_eval(results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7069978597622248"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bayes_estimators = int(results.loc[0, 'estimators'])\n",
    "best_bayes_params = ast.literal_eval(results.loc[0, 'params']).copy()\n",
    "\n",
    "best_bayes_model = lgb.LGBMClassifier(n_estimators=best_bayes_estimators, n_jobs = -1, \n",
    "                                       objective = 'binary', random_state = 50, **best_bayes_params,max_depth=5)\n",
    "\n",
    "best_bayes_model.fit(train_data, train_labels)\n",
    "\n",
    "test_features=np.array(test_data)\n",
    "train_features=np.array(train_data)\n",
    "test_predictions = best_bayes_model.predict_proba(test_features)[:, 1]\n",
    "train_predictions=best_bayes_model.predict_proba(train_features)[:, 1]\n",
    "\n",
    "\n",
    "#auc_best_model = roc_auc_score(test_labels, test_predictions)\n",
    "auc_best_model = roc_auc_score(test_labels, test_predictions)\n",
    "auc_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 0.7292016631698011,\n",
       " 'learning_rate': 0.010705097915397449,\n",
       " 'min_child_samples': 20,\n",
       " 'num_leaves': 39,\n",
       " 'reg_alpha': 0.6689164372874457,\n",
       " 'reg_lambda': 0.5471632266906857,\n",
       " 'subsample_for_bin': 100000,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bayes_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7967594193300186"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_best_model_train = roc_auc_score(train_labels, train_predictions)\n",
    "auc_best_model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict_proba(test_features)[:, 1]\n",
    "train_predictions=model.predict_proba(train_features)[:, 1]\n",
    "\n",
    "test_predictions_df = pd.DataFrame(test_predictions)\n",
    "train_predictions_df = pd.DataFrame(train_predictions)\n",
    "\n",
    "test_results = pd.concat([test_id, test_datestamp test_predictions_df, test_labels], axis=1)\n",
    "test_results = test_results.rename(columns={0: \"Score\"})\n",
    "test_results = test_results.sort_values(by='Score', axis=0, ascending=False)\n",
    "\n",
    "SumTest = pd.DataFrame(np.cumsum(test_results['Label']))\n",
    "SumTest = SumTest.rename(columns={'Label': 'Sum'})\n",
    "test_results = pd.concat([test_results, SumTest], axis=1)\n",
    "test_results.reset_index(inplace = True , drop=True)\n",
    "X_coordinates = pd.DataFrame(np.arange(1,(test_results.shape[0]+1))/(test_results.shape[0]))\n",
    "X_coordinates = X_coordinates.rename(columns={0: 'X_coordinates'})\n",
    "y_coordinates = pd.DataFrame(test_results['Sum']/test_results['Sum'].max())\n",
    "y_coordinates = y_coordinates.rename(columns={'Sum': 'y_coordinates'})\n",
    "test_results = pd.concat([test_results, X_coordinates,y_coordinates], axis=1)\n",
    "\n",
    "# train results\n",
    "train_results = pd.concat([train_id, train_datestamp, train_predictions_df, train_labels], axis=1)\n",
    "train_results = train_results.rename(columns={0:\"Score\"})\n",
    "train_results = train_results.sort_values(by='Score', axis=0, ascending=False)\n",
    "\n",
    "SumTrain = pd.DataFrame(np.cumsum(train_results['Label']))\n",
    "SumTrain = SumTrain.rename(columns={'Label':'Sum'})\n",
    "train_results = pd.concat([train_results, SumTrain], axis=1)\n",
    "\n",
    "train_results.reset_index(inplace = True , drop=True)\n",
    "X_coordinates = pd.DataFrame(np.arange(1,(train_results.shape[0]+1))/(train_results.shape[0]))\n",
    "X_coordinates = X_coordinates.rename(columns={0: 'X_coordinates'})\n",
    "y_coordinates = pd.DataFrame(train_results['Sum']/train_results['Sum'].max())\n",
    "y_coordinates = y_coordinates.rename(columns={'Sum': 'y_coordinates'})\n",
    "train_results = pd.concat([train_results, X_coordinates,y_coordinates], axis=1)\n",
    "\n",
    "test_results.to_csv(r'gbm_test_results.csv')\n",
    "train_results.to_csv(r'gbm_train_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1ebbc295c08>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.booster_.save_model(r'gbm_best_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = lgb.Booster(model_file=r'C:/Users/kzielinski003/Desktop/Chocolate/gbm_best_model_major.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
